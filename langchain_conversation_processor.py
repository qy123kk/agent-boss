#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºLangChainçš„æ™ºèƒ½å¯¹è¯å¤„ç†å™¨
ä½¿ç”¨ConversationBufferMemoryç®¡ç†å¯¹è¯å†å²ï¼Œæä¾›ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ™ºèƒ½å¤„ç†
"""

from typing import Dict, List, Optional, Any
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from conversation_state import ConversationStage
from qa_chain import create_llm
import json
import re


class LangChainConversationProcessor:
    """åŸºäºLangChainçš„æ™ºèƒ½å¯¹è¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.llm = None
        self.memory = None
        self.conversation_chain = None
        self._initialize_components()
        
        # å„é˜¶æ®µçš„å¤„ç†æç¤ºæ¨¡æ¿
        self.stage_prompts = {
            ConversationStage.COLLECTING_JOB_TYPE: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±‚èŒé¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·æ”¶é›†èŒä½ç±»å‹ä¿¡æ¯ã€‚

å½“å‰ä»»åŠ¡ï¼šç†è§£ç”¨æˆ·æƒ³è¦çš„èŒä½ç±»å‹

èŒä½ç±»å‹ç¤ºä¾‹ï¼š
- æŠ€æœ¯ç±»ï¼šPythonå¼€å‘å·¥ç¨‹å¸ˆã€å‰ç«¯å¼€å‘ã€Javaå·¥ç¨‹å¸ˆã€æ•°æ®åˆ†æå¸ˆ
- è®¾è®¡ç±»ï¼šUIè®¾è®¡å¸ˆã€UXè®¾è®¡å¸ˆã€å¹³é¢è®¾è®¡å¸ˆ
- ç®¡ç†ç±»ï¼šäº§å“ç»ç†ã€é¡¹ç›®ç»ç†ã€è¿è¥ç»ç†
- å…¶ä»–ï¼šé”€å”®ä»£è¡¨ã€äººäº‹ä¸“å‘˜ã€è´¢åŠ¡åˆ†æå¸ˆ

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ç¡®è®¤è¯ï¼ˆæ˜¯çš„ã€å¯¹ã€æ²¡é”™ã€å¥½çš„ã€å—¯ï¼‰ï¼Œæ£€æŸ¥å¯¹è¯å†å²ä¸­æ˜¯å¦æœ‰å¾…ç¡®è®¤çš„èŒä½ç±»å‹
2. å¦‚æœç”¨æˆ·è¾“å…¥å¦å®šè¯ï¼ˆä¸æ˜¯ã€ä¸å¯¹ã€é”™äº†ï¼‰ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°æ”¶é›†
3. å¦‚æœç”¨æˆ·è¾“å…¥å…·ä½“èŒä½åç§°æˆ–å…³é”®è¯ï¼Œæå–å¹¶ç¡®è®¤
4. å¦‚æœè¾“å…¥ä¸æ¸…æ¥šï¼Œå‹å¥½åœ°é‡æ–°è¯¢é—®

è¯·æ ¹æ®å¯¹è¯å†å²å’Œå½“å‰è¾“å…¥ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
    "understood": true/false,
    "job_type": "æå–çš„èŒä½ç±»å‹" æˆ– null,
    "confidence": 0.0-1.0,
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "action": "confirm/extract/retry"
}}
""",
            
            ConversationStage.COLLECTING_LOCATION: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±‚èŒé¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·æ”¶é›†å·¥ä½œåœ°ç‚¹ä¿¡æ¯ã€‚

å½“å‰ä»»åŠ¡ï¼šç†è§£ç”¨æˆ·æœŸæœ›çš„å·¥ä½œåœ°ç‚¹

åœ°ç‚¹ç¤ºä¾‹ï¼š
- ä¸€çº¿åŸå¸‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³
- æ–°ä¸€çº¿åŸå¸‚ï¼šæ­å·ã€æˆéƒ½ã€æ­¦æ±‰ã€å—äº¬ã€è¥¿å®‰
- ç‰¹æ®Šæƒ…å†µï¼šè¿œç¨‹åŠå…¬ã€åœ¨å®¶åŠå…¬ã€ä¸é™åœ°ç‚¹

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ç¡®è®¤è¯ï¼Œæ£€æŸ¥å¯¹è¯å†å²ä¸­æ˜¯å¦æœ‰å¾…ç¡®è®¤çš„åœ°ç‚¹
2. å¦‚æœç”¨æˆ·è¾“å…¥å¦å®šè¯ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°æ”¶é›†
3. å¦‚æœç”¨æˆ·è¾“å…¥åŸå¸‚åç§°ï¼Œæå–å¹¶ç¡®è®¤
4. æ”¯æŒå¤šä¸ªåŸå¸‚ï¼ˆå¦‚"åŒ—ä¸Šå¹¿"ï¼‰

è¯·æ ¹æ®å¯¹è¯å†å²å’Œå½“å‰è¾“å…¥ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
    "understood": true/false,
    "location": "æå–çš„åœ°ç‚¹" æˆ– null,
    "confidence": 0.0-1.0,
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "action": "confirm/extract/retry"
}}
""",
            
            ConversationStage.COLLECTING_SALARY: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±‚èŒé¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·æ”¶é›†è–ªèµ„æœŸæœ›ä¿¡æ¯ã€‚

å½“å‰ä»»åŠ¡ï¼šç†è§£ç”¨æˆ·çš„è–ªèµ„æœŸæœ›

è–ªèµ„æ ¼å¼ç¤ºä¾‹ï¼š
- èŒƒå›´ï¼š15-20Kã€10-15ä¸‡ã€8åƒ-1ä¸‡2
- å•ä¸€ï¼š15Kã€20ä¸‡ã€æœˆè–ª12000
- æ¨¡ç³Šï¼š20Kä»¥ä¸Šã€15ä¸‡å·¦å³ã€é¢è®®

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ç¡®è®¤è¯ï¼Œæ£€æŸ¥å¯¹è¯å†å²ä¸­æ˜¯å¦æœ‰å¾…ç¡®è®¤çš„è–ªèµ„
2. å¦‚æœç”¨æˆ·è¾“å…¥å¦å®šè¯ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°æ”¶é›†
3. å¦‚æœç”¨æˆ·è¾“å…¥æ•°å­—å’Œè–ªèµ„ç›¸å…³è¯æ±‡ï¼Œæå–å¹¶ç¡®è®¤
4. æ™ºèƒ½è¡¥å…¨å•ä½ï¼ˆå¦‚"15-20"å¯èƒ½æ˜¯"15-20K"ï¼‰

è¯·æ ¹æ®å¯¹è¯å†å²å’Œå½“å‰è¾“å…¥ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
    "understood": true/false,
    "salary": "æå–çš„è–ªèµ„" æˆ– null,
    "confidence": 0.0-1.0,
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "action": "confirm/extract/retry"
}}
"""
        }
    
    def _initialize_components(self):
        """åˆå§‹åŒ–LangChainç»„ä»¶"""
        try:
            # åˆ›å»ºLLM
            self.llm = create_llm(streaming=False)
            
            # åˆ›å»ºå¯¹è¯è®°å¿†
            self.memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True,
                human_prefix="ç”¨æˆ·",
                ai_prefix="åŠ©æ‰‹"
            )
            
            print("âœ… LangChainå¯¹è¯å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ LangChainå¯¹è¯å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm = None
            self.memory = None
    
    def process_user_input(self, user_input: str, current_stage: ConversationStage,
                          conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨LangChainå¤„ç†ç”¨æˆ·è¾“å…¥
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            current_stage: å½“å‰å¯¹è¯é˜¶æ®µ
            conversation_history: å¯¹è¯å†å²ï¼ˆç”¨äºæ¢å¤è®°å¿†ï¼‰
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        if not self.llm or not self.memory:
            return self._fallback_processing(user_input, current_stage)
        
        try:
            # æ¢å¤å¯¹è¯å†å²åˆ°è®°å¿†ä¸­
            if conversation_history:
                self._restore_memory(conversation_history)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥åˆ°è®°å¿†
            self.memory.chat_memory.add_user_message(user_input)
            
            # è·å–å¯¹è¯å†å²
            chat_history = self.memory.chat_memory.messages
            
            # æ„å»ºæç¤º
            prompt = self._build_langchain_prompt(user_input, current_stage, chat_history)
            
            # åˆ›å»ºLLMé“¾
            chain = LLMChain(
                llm=self.llm,
                prompt=PromptTemplate(
                    input_variables=["user_input", "chat_history"],
                    template=prompt
                ),
                memory=self.memory,
                verbose=False
            )
            
            # æ‰§è¡Œé“¾
            response = chain.run(
                user_input=user_input,
                chat_history=self._format_chat_history(chat_history)
            )
            
            # è§£æAIå“åº”
            result = self._parse_ai_response(response, user_input, current_stage)
            
            # æ·»åŠ AIå“åº”åˆ°è®°å¿†
            self.memory.chat_memory.add_ai_message(result.get("ai_response", ""))
            
            return result
            
        except Exception as e:
            print(f"LangChainå¤„ç†å¤±è´¥: {e}")
            return self._fallback_processing(user_input, current_stage)
    
    def _restore_memory(self, conversation_history: List[Dict]):
        """æ¢å¤å¯¹è¯å†å²åˆ°è®°å¿†ä¸­"""
        # æ¸…ç©ºå½“å‰è®°å¿†
        self.memory.chat_memory.clear()
        
        # æ¢å¤å†å²å¯¹è¯
        for message in conversation_history:
            if message.get('role') == 'user':
                self.memory.chat_memory.add_user_message(message.get('content', ''))
            elif message.get('role') == 'assistant':
                self.memory.chat_memory.add_ai_message(message.get('content', ''))
    
    def _format_chat_history(self, chat_history: List[BaseMessage]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        if not chat_history:
            return "æ— å¯¹è¯å†å²"
        
        formatted = []
        for message in chat_history[-6:]:  # æœ€è¿‘6æ¡æ¶ˆæ¯
            if isinstance(message, HumanMessage):
                formatted.append(f"ç”¨æˆ·: {message.content}")
            elif isinstance(message, AIMessage):
                formatted.append(f"åŠ©æ‰‹: {message.content}")
        
        return "\n".join(formatted)
    
    def _build_langchain_prompt(self, user_input: str, current_stage: ConversationStage,
                               chat_history: List[BaseMessage]) -> str:
        """æ„å»ºLangChainæç¤º"""
        if current_stage not in self.stage_prompts:
            return f"è¯·åˆ†æç”¨æˆ·è¾“å…¥ï¼š{user_input}"
        
        stage_prompt = self.stage_prompts[current_stage]
        
        prompt = f"""{stage_prompt}

å¯¹è¯å†å²ï¼š
{{chat_history}}

å½“å‰ç”¨æˆ·è¾“å…¥ï¼š{{user_input}}

è¯·ä»”ç»†åˆ†æå¯¹è¯ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¾“å…¥ï¼Œè¿”å›å‡†ç¡®çš„JSONæ ¼å¼ç»“æœã€‚
"""
        
        return prompt
    
    def _parse_ai_response(self, response: str, user_input: str, 
                          current_stage: ConversationStage) -> Dict[str, Any]:
        """è§£æAIå“åº”"""
        try:
            # å°è¯•è§£æJSON
            if '{' in response and '}' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
                result = json.loads(json_str)
                
                return {
                    "understood": result.get("understood", False),
                    "extracted_info": self._extract_info_from_result(result, current_stage),
                    "confidence": result.get("confidence", 0.0),
                    "ai_response": result.get("response", response),
                    "needs_clarification": not result.get("understood", False),
                    "action": result.get("action", "retry")
                }
            else:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                return self._extract_from_text(response, user_input, current_stage)
                
        except json.JSONDecodeError:
            return self._extract_from_text(response, user_input, current_stage)
    
    def _extract_info_from_result(self, result: Dict, current_stage: ConversationStage) -> Dict[str, Any]:
        """ä»AIç»“æœä¸­æå–ä¿¡æ¯"""
        extracted = {}
        
        if current_stage == ConversationStage.COLLECTING_JOB_TYPE:
            job_type = result.get("job_type")
            if job_type:
                extracted["job_type"] = job_type
        elif current_stage == ConversationStage.COLLECTING_LOCATION:
            location = result.get("location")
            if location:
                extracted["location"] = location
        elif current_stage == ConversationStage.COLLECTING_SALARY:
            salary = result.get("salary")
            if salary:
                extracted["salary"] = salary
        
        return extracted
    
    def _extract_from_text(self, response: str, user_input: str, 
                          current_stage: ConversationStage) -> Dict[str, Any]:
        """ä»æ–‡æœ¬å“åº”ä¸­æå–ä¿¡æ¯"""
        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘
        understood = "ç†è§£" in response and "ä¸ç†è§£" not in response
        
        return {
            "understood": understood,
            "extracted_info": {},
            "confidence": 0.3 if understood else 0.0,
            "ai_response": response,
            "needs_clarification": True,
            "action": "retry"
        }
    
    def _fallback_processing(self, user_input: str, current_stage: ConversationStage) -> Dict[str, Any]:
        """å›é€€å¤„ç†é€»è¾‘"""
        # ç®€å•çš„ç¡®è®¤è¯æ£€æµ‹
        confirmation_words = ["æ˜¯çš„", "å¯¹", "æ²¡é”™", "å¥½çš„", "å—¯", "æ˜¯", "å¯¹çš„", "æ­£ç¡®"]
        negation_words = ["ä¸æ˜¯", "ä¸å¯¹", "é”™äº†", "ä¸", "é”™è¯¯"]

        user_lower = user_input.lower().strip()

        if any(word in user_input for word in confirmation_words):
            # å°è¯•ä»å¯¹è¯å†å²ä¸­æå–å¾…ç¡®è®¤çš„ä¿¡æ¯
            extracted_info = self._extract_from_context(current_stage)

            return {
                "understood": True,
                "extracted_info": extracted_info,
                "confidence": 0.8,
                "ai_response": "å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†ã€‚",
                "needs_clarification": False,
                "action": "confirm"
            }
        elif any(word in user_input for word in negation_words):
            return {
                "understood": True,
                "extracted_info": {},
                "confidence": 0.8,
                "ai_response": "å¥½çš„ï¼Œè®©æˆ‘ä»¬é‡æ–°å¼€å§‹ã€‚",
                "needs_clarification": True,
                "action": "retry"
            }

        return {
            "understood": False,
            "extracted_info": {},
            "confidence": 0.0,
            "ai_response": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€ï¼Œè¯·å†è¯•ä¸€æ¬¡ã€‚",
            "needs_clarification": True,
            "action": "retry"
        }

    def _extract_from_context(self, current_stage: ConversationStage) -> Dict[str, Any]:
        """ä»å¯¹è¯ä¸Šä¸‹æ–‡ä¸­æå–å¾…ç¡®è®¤çš„ä¿¡æ¯"""
        if not self.memory or not self.memory.chat_memory.messages:
            return {}

        # è·å–æœ€è¿‘çš„AIæ¶ˆæ¯ï¼ŒæŸ¥æ‰¾å¾…ç¡®è®¤çš„ä¿¡æ¯
        recent_messages = self.memory.chat_memory.messages[-3:]  # æœ€è¿‘3æ¡æ¶ˆæ¯

        for message in reversed(recent_messages):
            if isinstance(message, AIMessage):
                content = message.content

                # æ ¹æ®å½“å‰é˜¶æ®µæå–ç›¸åº”ä¿¡æ¯
                if current_stage == ConversationStage.COLLECTING_JOB_TYPE:
                    # æŸ¥æ‰¾èŒä½ç±»å‹ç›¸å…³çš„ç¡®è®¤é—®é¢˜
                    patterns = [
                        r'æ‚¨æ˜¯æƒ³æ‰¾(.+?)çš„èŒä½å—',
                        r'æ‚¨æŒ‡çš„æ˜¯(.+?)å—',
                        r'èŒä½ç±»å‹æ˜¯(.+?)å¯¹å—',
                        r'(.+?)å¼€å‘å·¥ç¨‹å¸ˆ',
                        r'(.+?)å·¥ç¨‹å¸ˆ',
                        r'(.+?)è®¾è®¡å¸ˆ',
                        r'(.+?)ç»ç†'
                    ]

                    for pattern in patterns:
                        import re
                        match = re.search(pattern, content)
                        if match:
                            job_type = match.group(1).strip()
                            if job_type:
                                return {"job_type": job_type}

                elif current_stage == ConversationStage.COLLECTING_LOCATION:
                    # æŸ¥æ‰¾åœ°ç‚¹ç›¸å…³çš„ç¡®è®¤é—®é¢˜
                    patterns = [
                        r'å·¥ä½œåœ°ç‚¹æ˜¯(.+?)å¯¹å—',
                        r'æ‚¨å¸Œæœ›åœ¨(.+?)å·¥ä½œ',
                        r'åœ°ç‚¹æ˜¯(.+?)å—'
                    ]

                    for pattern in patterns:
                        import re
                        match = re.search(pattern, content)
                        if match:
                            location = match.group(1).strip()
                            if location:
                                return {"location": location}

                elif current_stage == ConversationStage.COLLECTING_SALARY:
                    # æŸ¥æ‰¾è–ªèµ„ç›¸å…³çš„ç¡®è®¤é—®é¢˜
                    patterns = [
                        r'è–ªèµ„æœŸæœ›æ˜¯(.+?)å¯¹å—',
                        r'è–ªèµ„(.+?)å—',
                        r'æœŸæœ›(.+?)å¯¹å—'
                    ]

                    for pattern in patterns:
                        import re
                        match = re.search(pattern, content)
                        if match:
                            salary = match.group(1).strip()
                            if salary:
                                return {"salary": salary}

        return {}
    
    def get_memory_summary(self) -> Dict[str, Any]:
        """è·å–è®°å¿†æ‘˜è¦"""
        if not self.memory:
            return {}
        
        messages = self.memory.chat_memory.messages
        return {
            "total_messages": len(messages),
            "recent_messages": [
                {
                    "type": type(msg).__name__,
                    "content": msg.content[:50] + "..." if len(msg.content) > 50 else msg.content
                }
                for msg in messages[-4:]
            ]
        }
    
    def clear_memory(self):
        """æ¸…ç©ºè®°å¿†"""
        if self.memory:
            self.memory.chat_memory.clear()


def test_langchain_processor():
    """æµ‹è¯•LangChainå¯¹è¯å¤„ç†å™¨"""
    processor = LangChainConversationProcessor()
    
    # æ¨¡æ‹Ÿå¯¹è¯æµç¨‹
    conversation_history = [
        {"role": "assistant", "content": "è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦çš„èŒä½ç±»å‹ï¼Ÿ"},
        {"role": "user", "content": "python"},
        {"role": "assistant", "content": "æ‚¨æ˜¯æƒ³æ‰¾Pythonå¼€å‘å·¥ç¨‹å¸ˆçš„èŒä½å—ï¼Ÿ"}
    ]
    
    # æµ‹è¯•ç¡®è®¤å›å¤
    result = processor.process_user_input(
        "æ˜¯çš„", 
        ConversationStage.COLLECTING_JOB_TYPE,
        conversation_history
    )
    
    print("ğŸ§ª æµ‹è¯•ç¡®è®¤å›å¤:")
    print(f"   ç†è§£: {result['understood']}")
    print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
    print(f"   æå–ä¿¡æ¯: {result['extracted_info']}")
    print(f"   AIå›å¤: {result['ai_response']}")
    
    # è·å–è®°å¿†æ‘˜è¦
    memory_summary = processor.get_memory_summary()
    print(f"\nğŸ“ è®°å¿†æ‘˜è¦: {memory_summary}")


if __name__ == "__main__":
    test_langchain_processor()
