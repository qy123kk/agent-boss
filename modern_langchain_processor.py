#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºæœ€æ–°LangChain 2025çš„æ™ºèƒ½å¯¹è¯å¤„ç†å™¨
ä½¿ç”¨LangGraphçš„StateGraphå’ŒMemorySaverè¿›è¡Œå¯¹è¯è®°å¿†ç®¡ç†
"""

from typing import Dict, List, Optional, Any, TypedDict
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, StateGraph
from conversation_state import ConversationStage
from qa_chain import create_llm
import json
import re


class ConversationState(TypedDict):
    """å¯¹è¯çŠ¶æ€ç±»å‹å®šä¹‰"""
    messages: List[BaseMessage]
    current_stage: str
    extracted_info: Dict[str, Any]
    confidence: float


class ModernLangChainProcessor:
    """åŸºäºæœ€æ–°LangChain 2025çš„æ™ºèƒ½å¯¹è¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.llm = None
        self.app = None
        self.memory = MemorySaver()
        self._initialize_components()
        
        # å„é˜¶æ®µçš„å¤„ç†æç¤ºæ¨¡æ¿
        self.stage_prompts = {
            ConversationStage.COLLECTING_JOB_TYPE: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±‚èŒé¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·æ”¶é›†èŒä½ç±»å‹ä¿¡æ¯ã€‚

åˆ†æå¯¹è¯å†å²å’Œå½“å‰ç”¨æˆ·è¾“å…¥ï¼Œç†è§£ç”¨æˆ·æƒ³è¦çš„èŒä½ç±»å‹ã€‚

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ç¡®è®¤è¯ï¼ˆæ˜¯çš„ã€å¯¹ã€æ²¡é”™ã€å¥½çš„ã€å—¯ï¼‰ï¼Œæ£€æŸ¥å¯¹è¯å†å²ä¸­æ˜¯å¦æœ‰å¾…ç¡®è®¤çš„èŒä½ç±»å‹
2. å¦‚æœç”¨æˆ·è¾“å…¥å¦å®šè¯ï¼ˆä¸æ˜¯ã€ä¸å¯¹ã€é”™äº†ï¼‰ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°æ”¶é›†
3. å¦‚æœç”¨æˆ·è¾“å…¥å…·ä½“èŒä½åç§°æˆ–å…³é”®è¯ï¼Œæå–å¹¶ç¡®è®¤
4. å¦‚æœè¾“å…¥ä¸æ¸…æ¥šï¼Œå‹å¥½åœ°é‡æ–°è¯¢é—®

èŒä½ç±»å‹ç¤ºä¾‹ï¼šPythonå¼€å‘å·¥ç¨‹å¸ˆã€UIè®¾è®¡å¸ˆã€äº§å“ç»ç†ã€æ•°æ®åˆ†æå¸ˆç­‰

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "understood": true/false,
    "job_type": "æå–çš„èŒä½ç±»å‹" æˆ– null,
    "confidence": 0.0-1.0,
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "action": "confirm/extract/retry"
}}
""",
            
            ConversationStage.COLLECTING_LOCATION: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±‚èŒé¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·æ”¶é›†å·¥ä½œåœ°ç‚¹ä¿¡æ¯ã€‚

åˆ†æå¯¹è¯å†å²å’Œå½“å‰ç”¨æˆ·è¾“å…¥ï¼Œç†è§£ç”¨æˆ·æœŸæœ›çš„å·¥ä½œåœ°ç‚¹ã€‚

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ç¡®è®¤è¯ï¼Œæ£€æŸ¥å¯¹è¯å†å²ä¸­æ˜¯å¦æœ‰å¾…ç¡®è®¤çš„åœ°ç‚¹
2. å¦‚æœç”¨æˆ·è¾“å…¥å¦å®šè¯ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°æ”¶é›†
3. å¦‚æœç”¨æˆ·è¾“å…¥åŸå¸‚åç§°ï¼Œæå–å¹¶ç¡®è®¤
4. æ”¯æŒå¤šä¸ªåŸå¸‚ï¼ˆå¦‚"åŒ—ä¸Šå¹¿"ï¼‰

åœ°ç‚¹ç¤ºä¾‹ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³ã€è¿œç¨‹åŠå…¬ç­‰

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "understood": true/false,
    "location": "æå–çš„åœ°ç‚¹" æˆ– null,
    "confidence": 0.0-1.0,
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "action": "confirm/extract/retry"
}}
""",
            
            ConversationStage.COLLECTING_SALARY: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±‚èŒé¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·æ”¶é›†è–ªèµ„æœŸæœ›ä¿¡æ¯ã€‚

åˆ†æå¯¹è¯å†å²å’Œå½“å‰ç”¨æˆ·è¾“å…¥ï¼Œç†è§£ç”¨æˆ·çš„è–ªèµ„æœŸæœ›ã€‚

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·è¾“å…¥ç¡®è®¤è¯ï¼Œæ£€æŸ¥å¯¹è¯å†å²ä¸­æ˜¯å¦æœ‰å¾…ç¡®è®¤çš„è–ªèµ„
2. å¦‚æœç”¨æˆ·è¾“å…¥å¦å®šè¯ï¼Œè¡¨ç¤ºéœ€è¦é‡æ–°æ”¶é›†
3. å¦‚æœç”¨æˆ·è¾“å…¥æ•°å­—å’Œè–ªèµ„ç›¸å…³è¯æ±‡ï¼Œæå–å¹¶ç¡®è®¤
4. æ™ºèƒ½è¡¥å…¨å•ä½ï¼ˆå¦‚"15-20"å¯èƒ½æ˜¯"15-20K"ï¼‰

è–ªèµ„æ ¼å¼ç¤ºä¾‹ï¼š15-20Kã€æœˆè–ª1ä¸‡ã€å¹´è–ª30ä¸‡ã€é¢è®®ç­‰

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "understood": true/false,
    "salary": "æå–çš„è–ªèµ„" æˆ– null,
    "confidence": 0.0-1.0,
    "response": "ç»™ç”¨æˆ·çš„å›å¤",
    "action": "confirm/extract/retry"
}}
"""
        }
    
    def _initialize_components(self):
        """åˆå§‹åŒ–LangGraphç»„ä»¶"""
        try:
            # åˆ›å»ºLLM
            self.llm = create_llm(streaming=False)
            
            # åˆ›å»ºStateGraphå·¥ä½œæµ
            workflow = StateGraph(ConversationState)
            
            # æ·»åŠ å¤„ç†èŠ‚ç‚¹
            workflow.add_node("process_message", self._process_message_node)
            
            # æ·»åŠ è¾¹
            workflow.add_edge(START, "process_message")
            
            # ç¼–è¯‘åº”ç”¨ï¼Œæ·»åŠ è®°å¿†æ£€æŸ¥ç‚¹
            self.app = workflow.compile(checkpointer=self.memory)
            
            print("âœ… ç°ä»£LangChainå¯¹è¯å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ ç°ä»£LangChainå¯¹è¯å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm = None
            self.app = None
    
    def _process_message_node(self, state: ConversationState) -> ConversationState:
        """å¤„ç†æ¶ˆæ¯çš„èŠ‚ç‚¹å‡½æ•°"""
        messages = state["messages"]
        current_stage = state.get("current_stage", "job_type")
        
        if not messages:
            return state
        
        # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        latest_message = messages[-1]
        if not isinstance(latest_message, HumanMessage):
            return state
        
        user_input = latest_message.content
        
        # æ„å»ºåˆ†ææç¤º
        stage_enum = self._string_to_stage(current_stage)
        prompt = self._build_analysis_prompt(user_input, messages, stage_enum)
        
        try:
            # è°ƒç”¨LLMåˆ†æ
            response = self.llm.invoke([SystemMessage(content=prompt)])
            
            # è§£æå“åº”
            result = self._parse_llm_response(response.content, user_input, stage_enum)
            
            # ç”ŸæˆAIå›å¤æ¶ˆæ¯
            ai_message = AIMessage(content=result["ai_response"])
            
            return {
                "messages": messages + [ai_message],
                "current_stage": current_stage,
                "extracted_info": result["extracted_info"],
                "confidence": result["confidence"]
            }
            
        except Exception as e:
            print(f"LLMå¤„ç†å¤±è´¥: {e}")
            # å›é€€å¤„ç†
            fallback_result = self._fallback_processing(user_input, stage_enum)
            ai_message = AIMessage(content=fallback_result["ai_response"])
            
            return {
                "messages": messages + [ai_message],
                "current_stage": current_stage,
                "extracted_info": fallback_result["extracted_info"],
                "confidence": fallback_result["confidence"]
            }
    
    def _build_analysis_prompt(self, user_input: str, messages: List[BaseMessage], 
                              current_stage: ConversationStage) -> str:
        """æ„å»ºåˆ†ææç¤º"""
        if current_stage not in self.stage_prompts:
            return f"è¯·åˆ†æç”¨æˆ·è¾“å…¥ï¼š{user_input}"
        
        stage_prompt = self.stage_prompts[current_stage]
        
        # æ ¼å¼åŒ–å¯¹è¯å†å²
        history_text = self._format_message_history(messages[:-1])  # æ’é™¤æœ€æ–°æ¶ˆæ¯
        
        prompt = f"""{stage_prompt}

å¯¹è¯å†å²ï¼š
{history_text}

å½“å‰ç”¨æˆ·è¾“å…¥ï¼š"{user_input}"

è¯·ä»”ç»†åˆ†æå¯¹è¯ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¾“å…¥ï¼Œè¿”å›å‡†ç¡®çš„JSONæ ¼å¼ç»“æœã€‚
"""
        
        return prompt
    
    def _format_message_history(self, messages: List[BaseMessage]) -> str:
        """æ ¼å¼åŒ–æ¶ˆæ¯å†å²"""
        if not messages:
            return "æ— å¯¹è¯å†å²"
        
        formatted = []
        for message in messages[-6:]:  # æœ€è¿‘6æ¡æ¶ˆæ¯
            if isinstance(message, HumanMessage):
                formatted.append(f"ç”¨æˆ·: {message.content}")
            elif isinstance(message, AIMessage):
                formatted.append(f"åŠ©æ‰‹: {message.content}")
        
        return "\n".join(formatted)
    
    def _parse_llm_response(self, response: str, user_input: str, 
                           current_stage: ConversationStage) -> Dict[str, Any]:
        """è§£æLLMå“åº”"""
        try:
            # å°è¯•è§£æJSON
            if '{' in response and '}' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
                result = json.loads(json_str)
                
                return {
                    "understood": result.get("understood", False),
                    "extracted_info": self._extract_info_from_result(result, current_stage),
                    "confidence": result.get("confidence", 0.0),
                    "ai_response": result.get("response", response),
                    "needs_clarification": not result.get("understood", False),
                    "action": result.get("action", "retry")
                }
            else:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                return self._extract_from_text(response, user_input, current_stage)
                
        except json.JSONDecodeError:
            return self._extract_from_text(response, user_input, current_stage)
    
    def _extract_info_from_result(self, result: Dict, current_stage: ConversationStage) -> Dict[str, Any]:
        """ä»AIç»“æœä¸­æå–ä¿¡æ¯"""
        extracted = {}
        
        if current_stage == ConversationStage.COLLECTING_JOB_TYPE:
            job_type = result.get("job_type")
            if job_type:
                extracted["job_type"] = job_type
        elif current_stage == ConversationStage.COLLECTING_LOCATION:
            location = result.get("location")
            if location:
                extracted["location"] = location
        elif current_stage == ConversationStage.COLLECTING_SALARY:
            salary = result.get("salary")
            if salary:
                extracted["salary"] = salary
        
        return extracted
    
    def _extract_from_text(self, response: str, user_input: str, 
                          current_stage: ConversationStage) -> Dict[str, Any]:
        """ä»æ–‡æœ¬å“åº”ä¸­æå–ä¿¡æ¯"""
        understood = "ç†è§£" in response and "ä¸ç†è§£" not in response
        
        return {
            "understood": understood,
            "extracted_info": {},
            "confidence": 0.3 if understood else 0.0,
            "ai_response": response,
            "needs_clarification": True,
            "action": "retry"
        }
    
    def _fallback_processing(self, user_input: str, current_stage: ConversationStage) -> Dict[str, Any]:
        """å›é€€å¤„ç†é€»è¾‘"""
        confirmation_words = ["æ˜¯çš„", "å¯¹", "æ²¡é”™", "å¥½çš„", "å—¯", "æ˜¯", "å¯¹çš„", "æ­£ç¡®"]
        negation_words = ["ä¸æ˜¯", "ä¸å¯¹", "é”™äº†", "ä¸", "é”™è¯¯"]
        
        if any(word in user_input for word in confirmation_words):
            return {
                "understood": True,
                "extracted_info": {},  # éœ€è¦ä»ä¸Šä¸‹æ–‡ä¸­è·å–
                "confidence": 0.8,
                "ai_response": "å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†ã€‚",
                "needs_clarification": False,
                "action": "confirm"
            }
        elif any(word in user_input for word in negation_words):
            return {
                "understood": True,
                "extracted_info": {},
                "confidence": 0.8,
                "ai_response": "å¥½çš„ï¼Œè®©æˆ‘ä»¬é‡æ–°å¼€å§‹ã€‚",
                "needs_clarification": True,
                "action": "retry"
            }
        
        return {
            "understood": False,
            "extracted_info": {},
            "confidence": 0.0,
            "ai_response": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€ï¼Œè¯·å†è¯•ä¸€æ¬¡ã€‚",
            "needs_clarification": True,
            "action": "retry"
        }
    
    def _string_to_stage(self, stage_str: str) -> ConversationStage:
        """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºConversationStageæšä¸¾"""
        stage_mapping = {
            "job_type": ConversationStage.COLLECTING_JOB_TYPE,
            "location": ConversationStage.COLLECTING_LOCATION,
            "salary": ConversationStage.COLLECTING_SALARY
        }
        return stage_mapping.get(stage_str, ConversationStage.COLLECTING_JOB_TYPE)
    
    def process_user_input(self, user_input: str, current_stage: ConversationStage,
                          conversation_history: List[Dict] = None, thread_id: str = "default") -> Dict[str, Any]:
        """
        ä½¿ç”¨ç°ä»£LangChainå¤„ç†ç”¨æˆ·è¾“å…¥
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            current_stage: å½“å‰å¯¹è¯é˜¶æ®µ
            conversation_history: å¯¹è¯å†å²ï¼ˆç”¨äºå…¼å®¹ï¼‰
            thread_id: çº¿ç¨‹ID
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        if not self.app:
            return self._fallback_processing(user_input, current_stage)
        
        try:
            # æ„å»ºåˆå§‹çŠ¶æ€
            messages = []
            
            # ä»å¯¹è¯å†å²æ¢å¤æ¶ˆæ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if conversation_history:
                for msg in conversation_history:
                    if msg.get('role') == 'user':
                        messages.append(HumanMessage(content=msg.get('content', '')))
                    elif msg.get('role') == 'assistant':
                        messages.append(AIMessage(content=msg.get('content', '')))
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append(HumanMessage(content=user_input))
            
            # è°ƒç”¨LangGraphåº”ç”¨
            result = self.app.invoke(
                {
                    "messages": messages,
                    "current_stage": current_stage.value,
                    "extracted_info": {},
                    "confidence": 0.0
                },
                config={"configurable": {"thread_id": thread_id}}
            )
            
            return {
                "understood": result["confidence"] > 0.5,
                "extracted_info": result["extracted_info"],
                "confidence": result["confidence"],
                "ai_response": result["messages"][-1].content if result["messages"] else "å¤„ç†å®Œæˆ",
                "needs_clarification": result["confidence"] < 0.5,
                "action": "confirm" if result["confidence"] > 0.7 else "retry"
            }
            
        except Exception as e:
            print(f"ç°ä»£LangChainå¤„ç†å¤±è´¥: {e}")
            return self._fallback_processing(user_input, current_stage)
    
    def get_memory_summary(self, thread_id: str = "default") -> Dict[str, Any]:
        """è·å–è®°å¿†æ‘˜è¦"""
        try:
            # è·å–æ£€æŸ¥ç‚¹çŠ¶æ€
            state = self.app.get_state(config={"configurable": {"thread_id": thread_id}})
            if state and state.values:
                messages = state.values.get("messages", [])
                return {
                    "total_messages": len(messages),
                    "recent_messages": [
                        {
                            "type": type(msg).__name__,
                            "content": msg.content[:50] + "..." if len(msg.content) > 50 else msg.content
                        }
                        for msg in messages[-4:]
                    ]
                }
        except Exception as e:
            print(f"è·å–è®°å¿†æ‘˜è¦å¤±è´¥: {e}")
        
        return {"total_messages": 0, "recent_messages": []}
    
    def clear_memory(self, thread_id: str = "default"):
        """æ¸…ç©ºè®°å¿†"""
        try:
            # LangGraphçš„MemorySaverä¼šè‡ªåŠ¨ç®¡ç†çŠ¶æ€
            # è¿™é‡Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é‡æ–°åˆå§‹åŒ–æ¥æ¸…ç©ºç‰¹å®šçº¿ç¨‹çš„è®°å¿†
            pass
        except Exception as e:
            print(f"æ¸…ç©ºè®°å¿†å¤±è´¥: {e}")


def test_modern_processor():
    """æµ‹è¯•ç°ä»£LangChainå¯¹è¯å¤„ç†å™¨"""
    processor = ModernLangChainProcessor()
    
    # æ¨¡æ‹Ÿå¯¹è¯æµç¨‹
    conversation_history = [
        {"role": "assistant", "content": "è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦çš„èŒä½ç±»å‹ï¼Ÿ"},
        {"role": "user", "content": "python"},
        {"role": "assistant", "content": "æ‚¨æ˜¯æƒ³æ‰¾Pythonå¼€å‘å·¥ç¨‹å¸ˆçš„èŒä½å—ï¼Ÿ"}
    ]
    
    # æµ‹è¯•ç¡®è®¤å›å¤
    result = processor.process_user_input(
        "æ˜¯çš„", 
        ConversationStage.COLLECTING_JOB_TYPE,
        conversation_history,
        thread_id="test_1"
    )
    
    print("ğŸ§ª æµ‹è¯•ç°ä»£LangChainå¤„ç†å™¨:")
    print(f"   ç†è§£: {result['understood']}")
    print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
    print(f"   æå–ä¿¡æ¯: {result['extracted_info']}")
    print(f"   AIå›å¤: {result['ai_response']}")
    
    # è·å–è®°å¿†æ‘˜è¦
    memory_summary = processor.get_memory_summary("test_1")
    print(f"\nğŸ“ è®°å¿†æ‘˜è¦: {memory_summary}")


if __name__ == "__main__":
    test_modern_processor()
